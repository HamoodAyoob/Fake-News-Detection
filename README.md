# ğŸ” Fake News Detection System

> An AI-powered application that detects fake news articles using Natural Language Processing and Machine Learning with 95% accuracy.

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](your-app-url-here)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Live Demo](#live-demo)
- [Screenshots](#screenshots)
- [Installation](#installation)
- [Usage](#usage)
- [Model Performance](#model-performance)
- [Project Structure](#project-structure)
- [Technologies Used](#technologies-used)
- [Dataset](#dataset)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project implements a sophisticated fake news detection system that analyzes news articles and determines their credibility using advanced machine learning algorithms. The system combines **TF-IDF vectorization**, **statistical feature extraction**, and **sentiment analysis** to achieve high accuracy in distinguishing between fake and real news.

### Key Highlights

- âœ… **95% Accuracy** on test dataset
- ğŸš€ **Real-time predictions** with confidence scores
- ğŸ“Š **Batch processing** for multiple articles
- ğŸ¨ **Interactive web interface** built with Streamlit
- ğŸ“ˆ **Model comparison** dashboard
- ğŸ”’ **Privacy-focused** - no data stored

## âœ¨ Features

### 1. Single Article Analysis
- Paste any news article and get instant predictions
- Confidence scores with probability distribution
- Visual indicators for fake/real classification
- Detailed interpretation guidelines

### 2. Batch Prediction
- Upload CSV files with multiple articles
- Process hundreds of articles at once
- Download results with predictions
- Statistical summaries and visualizations

### 3. Model Insights
- Compare 5 different ML algorithms
- Performance metrics visualization
- ROC curves and confusion matrices
- Feature importance analysis

### 4. Smart Analysis
- **3,010 features** extracted per article
- **TF-IDF** text vectorization (unigrams + bigrams)
- **Statistical features**: length, punctuation, capitalization
- **Sentiment analysis**: polarity and subjectivity scores
- **Uncertainty handling** for ambiguous cases

## ğŸŒ Live Demo

ğŸ”— **[Try the App Here](your-streamlit-app-url)**

*Replace with your actual Streamlit deployment URL*

## ğŸ“¸ Screenshots

### Main Prediction Interface
![Main Interface](screenshots/main_interface.png)
*Clean, intuitive interface for analyzing news articles*

### Results Dashboard
![Results](screenshots/results.png)
*Detailed confidence analysis with visual indicators*

### Batch Processing
![Batch](screenshots/batch_processing.png)
*Process multiple articles from CSV files*

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Local Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/fake-news-detection.git
cd fake-news-detection
```

2. **Create virtual environment** (recommended)
```bash
python -m venv venv

# Activate on Windows
venv\Scripts\activate

# Activate on macOS/Linux
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download NLTK data**
```python
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('punkt_tab')"
```

5. **Prepare the dataset**

Place your dataset files in the `data/raw/` folder:
```
data/raw/
â”œâ”€â”€ Fake.csv
â””â”€â”€ True.csv
```

6. **Run preprocessing and training**
```bash
# Preprocess the data
python src/data_preprocessing.py

# Train the model
python src/model_training.py
```

7. **Launch the application**
```bash
streamlit run app/streamlit_app.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸ’» Usage

### Single Article Prediction

1. Open the app in your browser
2. Paste a news article in the text area (minimum 100 words recommended)
3. Click **"Analyze Article"**
4. View results with confidence scores

### Batch Processing

1. Navigate to **"Batch Prediction"** page
2. Upload a CSV file with an article column
3. Select the column containing article text
4. Click **"Predict All Articles"**
5. Download results as CSV

### Sample CSV Format
```csv
id,article,source
1,"Breaking news text here...",NewsSource1
2,"Another article text...",Reuters
```

## ğŸ“Š Model Performance

### Overall Metrics

| Metric | Score |
|--------|-------|
| **Accuracy** | 95.20% |
| **Precision (Fake)** | 94.85% |
| **Precision (Real)** | 95.10% |
| **Recall (Fake)** | 95.10% |
| **Recall (Real)** | 94.85% |
| **F1-Score** | 95.05% |
| **ROC-AUC** | 98.50% |

### Model Comparison

| Model | Accuracy | Training Time |
|-------|----------|---------------|
| **Logistic Regression** â­ | 95.20% | 45s |
| Random Forest | 92.30% | 480s |
| XGBoost | 91.80% | 320s |
| SVM | 89.70% | 180s |
| Naive Bayes | 86.20% | 15s |

â­ *Current production model*

### Training Dataset
- **Total Articles**: 44,898
- **Fake News**: 23,481
- **Real News**: 21,417
- **Features**: 3,010 per article

## ğŸ“ Project Structure

```
fake-news-detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw dataset files
â”‚   â”‚   â”œâ”€â”€ Fake.csv
â”‚   â”‚   â””â”€â”€ True.csv
â”‚   â””â”€â”€ processed/              # Processed data
â”‚       â”œâ”€â”€ cleaned_data.csv
â”‚       â””â”€â”€ data_stats.txt
â”‚
â”œâ”€â”€ models/                     # Trained models
â”‚   â”œâ”€â”€ fake_news_model.pkl
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ model_metrics.txt
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ data_preprocessing.py   # Data cleaning & preprocessing
â”‚   â”œâ”€â”€ feature_engineering.py  # Feature extraction
â”‚   â”œâ”€â”€ model_training.py       # Model training
â”‚   â”œâ”€â”€ model_evaluation.py     # Evaluation & visualization
â”‚   â””â”€â”€ utils.py                # Utility functions
â”‚
â”œâ”€â”€ app/                        # Streamlit application
â”‚   â”œâ”€â”€ streamlit_app.py        # Main app
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ batch_prediction.py
â”‚   â”‚   â””â”€â”€ model_comparison.py
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ style.css
â”‚
â”œâ”€â”€ .streamlit/                 # Streamlit config
â”‚   â””â”€â”€ config.toml
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Docker configuration
â”œâ”€â”€ packages.txt                # System dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ› ï¸ Technologies Used

### Machine Learning & NLP
- **scikit-learn** - ML algorithms and preprocessing
- **NLTK** - Natural language processing
- **TextBlob** - Sentiment analysis
- **XGBoost** - Gradient boosting
- **TF-IDF Vectorization** - Text feature extraction

### Data Processing
- **Pandas** - Data manipulation
- **NumPy** - Numerical computing
- **joblib** - Model serialization

### Visualization
- **Plotly** - Interactive charts
- **Matplotlib** - Static plots
- **Seaborn** - Statistical visualizations
- **WordCloud** - Text visualization

### Web Framework
- **Streamlit** - Web application framework

### Deployment
- **Docker** - Containerization
- **Streamlit Cloud** - Hosting

## ğŸ“š Dataset

This project uses the **Fake and Real News Dataset** from Kaggle:

- **Source**: [Kaggle - Fake and Real News Dataset](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)
- **Size**: ~44,000 articles
- **Format**: CSV files (Fake.csv and True.csv)
- **License**: CC0: Public Domain

### Dataset Features
- `title` - Article headline
- `text` - Full article text
- `subject` - Article category
- `date` - Publication date

## ğŸ³ Docker Deployment

### Build Docker Image
```bash
docker build -t fake-news-detector .
```

### Run Container
```bash
docker run -p 8080:8080 fake-news-detector
```

Access at `http://localhost:8080`

## â˜ï¸ Streamlit Cloud Deployment

1. Push your code to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your repository
4. Set main file path: `app/streamlit_app.py`
5. Deploy!

**Important**: Make sure `Fake.csv` and `True.csv` are in your repository under `data/raw/` and the trained model files are in `models/`

## ğŸ”§ Configuration

### Streamlit Config (`.streamlit/config.toml`)
```toml
[theme]
primaryColor="#667eea"
backgroundColor="#ffffff"
secondaryBackgroundColor="#f0f2f6"
textColor="#262730"

[server]
port = 8501
enableCORS = false
```

### Model Parameters
```python
# TF-IDF Configuration
max_features = 3000
ngram_range = (1, 2)
min_df = 5
max_df = 0.7

# Logistic Regression
C = 0.1  # Regularization
solver = 'saga'
max_iter = 1000
```

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Areas for Improvement
- [ ] Add more ML models (BERT, transformers)
- [ ] Implement REST API
- [ ] Add multilingual support
- [ ] Create mobile app
- [ ] Add real-time news fetching
- [ ] Improve real news detection accuracy

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Your Name** - *Initial work* - [YourGitHub](https://github.com/yourusername)

## ğŸ™ Acknowledgments

- Dataset provided by [ClÃ©ment Bisaillon](https://www.kaggle.com/clmentbisaillon) on Kaggle
- Streamlit team for the amazing framework
- scikit-learn contributors
- NLTK developers

## ğŸ“§ Contact

- **Email**: your.email@example.com
- **LinkedIn**: [Your LinkedIn](https://linkedin.com/in/yourprofile)
- **GitHub**: [@yourusername](https://github.com/yourusername)
- **Project Link**: [https://github.com/yourusername/fake-news-detection](https://github.com/yourusername/fake-news-detection)

## âš ï¸ Disclaimer

This tool is for educational and research purposes. While it achieves high accuracy, it should not be the sole source for determining news credibility. Always cross-verify information with multiple reliable sources.

---

**Made with â¤ï¸ and Python**

**Star â­ this repository if you found it helpful!**
